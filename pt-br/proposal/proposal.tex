\documentclass[a4paper,12pt]{article}

\usepackage{authblk}
\usepackage[sort]{natbib}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{color}

\usepackage{indentfirst}

\newcommand{\etal}{et~al.}
\newcommand{\protosection}[1]{\vspace{1ex}\noindent\textbf{#1}}

%\linespread{0.96}
\title{\textbf{Automatic Parallelization for Heterogeneous Computing}}
\date{Prospective Ph.D. supervisor - Dr. Zheng Wang}
\author[]{Rodrigo Caetano Rocha}

\newcommand\FIXME[1]{\textcolor{red}{FIX:}\textcolor{red}{#1}}

\begin{document}
\maketitle

\begin{abstract}

\end{abstract}

\section{Introdução} 

Durante os últimos anos, os computadores modernos estão cada vez mais paralelos e
heterogêneos~\cite{mohanty12,misailovic13}. Com arquiteturas paralelas sendo
amplamente difundido, a programação paralela deve estender-se para além de sua esfera tradicional de
aplicações científicas~\cite{li09}. O objetivo final de um programador em um
ambiente de computação moderno é escrever aplicações escaláveis que podem aproveitar por completo
de todos os recursos disponíveis, uma vez que paralelização é um aspecto
importante que pode produzir grande impacto sobre o desempenho e
consumo de energia~\cite{cockx10}. No entanto, programação paralela é conhecida por ser
difícil e sujeita a erros, impondo vários desafios ao programador~\cite{cockx10,mccool10,mccool12}.
Assim, a dificuldade de
desenvolvimento de software paralelo é um dos principais obstáculos para um programador médio
explorar consideravelmente o poder computacional que diferentes multiprocessadores
oferecem~\cite{misailovic13}.

A fim de aproveitar de forma transparente todos os recursos disponíveis por
arquiteturas paralelas, paralelização automática é uma otimização que produz código paralelo que é semanticamente equivalente a um código seqüencial recebido como entrada. No entanto, paralelização automática é um problema difícil uma vez que o código paralelo deve ser correto e também executar de forma eficiente na máquina alvo~\cite{williams99}. Apesar do interesse de  pesquisa intenso na área, ainda não somos capazes resolver fora de alguns nichos de domínios~\cite{tournavitis09,wang14a}. Melhorar o desempenho dos programas para multiprocessadores apresenta um desafio porque mesmo quando existe um nível de paralelismo, é difícil para um compilador analisar e identificar todas as dependências reais entre os potenciais \textit{threads} paralelas~\cite{hammond98}.

Além disso, embora esta área tenha sido amplamente estudado, ainda há muito para ser explorado em relação a paralelização automática que também otimiza para consumo de energia, sistemas embarcados~\cite{cordes10} ou outras arquiteturas emergentes de computação~\cite{baskaran10}, tais como processadores massivamente paralelos, incluindo unidades de processamento gráfico (GPUs), processadores de muitos núcleos integrados (MICs), e outros.

Considerando que a maioria dos programas são executados indefinidamente muito mais vezes do que são compilados, compiladores podem suportar otimizações custosas durante o processo de compilação. Trabalhos anteriores sugerem diferentes abordagens para paralelização automática baseado em técnicas de aprendizagem de máquina~\cite{tournavitis09,wang14a} e também em computação evolutiva~\cite{walsh95,walsh96,williams96,williams99}.

Propomos investigar abordagens otimistas, com base no aprendizado de máquina e computação evolutiva, para a paralelização automática, aproveitando ainda das arquiteturas heterogêneas disponíveis, referente a paralelismo e consumo de energia. A abordagem otimista permite superar as limitações das abordagens tradicionais baseadas apenas na análise estática, penalizando precisão com soluções probabilísticas.

\section{Trabalhos relacionados}

Nesta seção, apresentamos uma visão geral dos vários trabalhos relacionados sobre paralelização automática de código seqüencial, onde discutimos várias abordagens de paralelização para ambos sistemas multi-core e heterogêneos.

\subsection{Paralelismo automático baseado em análise estática}

Inúmeros trabalhos iníciais fazem uso de técnicas de análise estática a fim de paralelizar laços afins~\cite{kuck81,padua93,blume94,lim97,bondhugula08,misailovic13}. Contudo, paralelização automática baseada em análise estática é um desafio e limitada ao tipo de código capaz de paralelizar~\cite{bruening98,kennedy01,chen03}. A fim de identificar regiões paralelas no código, deve-se usar análises complexas interprocedurais para provar que o código não possui dependências de dados para todas as entradas possíveis. Códigos típicos visados por estes compiladores consistem de laços aninhados com acessos afins de arranjos escrito em uma linguagem com aliasing limitado. Grandes sistemas escritos em linguagens modernas geralmente contêm vários módulos e aliasing de memória, o que os tornam não passíveis de paralelização automática. Além disso, código cujo padrão de acesso à memória é indeterminável em tempo de compilação devido às dependências das entradas do programa podem ser impraticável para esses compiladores paralelizarem~\cite{bruening98}.

\subsection{Paralelismo especulativo no nível de threads}

Em contraste com a paralelização automático que visa gerar código paralelo, a abordagem de especulação no nível de thread (TLS) realiza paralelização de código seqüencial em tempo de execução de maneira especulativa. Consiste em selecionar regiões de código para executar em paralelo, geralmente contando com hardware especializado para detectar violações de dependência e re-executar seções com conflito de tal forma que a semântica de execução seqüencial é preservada~\cite{hammond98,chen03,wu08}. Embora TLS supera as limitações intrínseca às ferramentas conservadoras de paralelização automática em tempo de compilação, extraindo segmentos paralelos de maneira otimista e garantindo a ausência de violações de dependência dados apenas em tempo de execução. TLS geralmente requer um hardware especializado e os custos associadas com a manutenção do estado especulativo é um obstáculo significativo para a sua utilização~\cite{yiapanis13}.

\subsection{Abordagens baseadas em aprendizagem de máquina}

Além da detecção de paralelismo, mecanismos de paralelização automática devem também determinar se é rentável para paralelizar um laço e como o laço deve ser escalonado se a execução paralela for rentável. Trabalhos recentes~\cite{wang09,tournavitis09,wang14a} têm utilizado técnicas de aprendizagem de máquina para integrar o mapeamento automático e portátil com a descoberta automático de paralelismo. Mecanismos de previsão são aplicados a cada laço candidato à paralelismo, decidindo se e como o mapeamento paralelo deve ser realizado.

\subsection{Paralelismo automático baseado em computação evolucionária}

Computação evolutiva foi previamente aplicada a paralelização automática e também várias outras otimizações em compiladores~\cite{walsh95,walsh96,williams96,williams99,schulte14a}. Trabalhos anteriores sobre paralelização evolutiva não faz nenhuma tentativa de analisar o código sequencial original, em vez disso, tenta realizar diretamente a paralelização de laços e instruções. Abordagens evolutivas têm uma estratégia de paralelização otimista, experimentalmente validando os melhores indivíduos. Embora esta abordagem não é limitada por técnicas de análise de dependências, a abordagem evolutiva produz resultados probabilísticos, apenas com garantias estatísticas. A correção do código paralelo resultante é determinada pela função de avaliação, que compara a saída produzida pelo código seqüencial original e a saída produzida por cada código paralelo gerado.

\subsection{Paralelização automática para sistemas heterogêneos}

Embora a maioria dos estudos focam em paralelização automática para arquiteturas homogéneas de memória compartilhada (somente CPU), tem havido alguns trabalhos recentes em direção a paralelização para arquiteturas heterogêneas (geralmente com GPUs). A abordagem usual consiste em detectar laços afins que podem ser paralelizados e executados de forma mais eficiente na GPU ao invés da CPU. Tem havido trabalhos mais focados em ambas as transformações de baixo nível (por exemplo, Leung~\etal~\cite{leung09} estende a máquina virtual do Java para paralelização de bytecodes Java para GPUs) e transformações de alto nível (por exemplo, Baskaran~\etal~\cite{baskaran08,baskaran10} propõem uma transformação entre códigos fonte, utilizando um modelo de compilador poliédrico, também paralelizando para GPUs).

\subsection{Desempenho versus precisão}
\label{subsec:perfvsacc}

Existem inúmeros trabalhos sobre o equilíbro entre desempenho e precisão em diferentes áreas. Em contraste com as abordagens tradicionais, vários trabalhos discutem arquiteturas probabilísticas e aproximadas, a fim de projetar hardwares com melhor desempenho em matéria de consumo de energia, tempo de execução, espaço físico e simplicidade arquitetural~\cite{palem09,palem12,lingamneni12,kirsch12}. Alguns trabalhos recentes também propõem numerosas transformações de código visando precisão com melhor desempenho, tempo de execução e o consumo de recursos, enquanto produz pequenas perdas de precisão~\cite{misailovic11,douskos11,zhu12}.

\section{Temas de pesquisa}\label{sec:research-dir}

%\FIXME{ZW: Try to summarize your approach in the first paragraph of this section}

É amplamente conhecido que a detecção de paralelismo por compiladores estáticos em programas grandes e gerais é um desafio~\cite{kennedy01,chen03}. A fim de superar as limitações de paralelização automática com base em análise estática para multiprocessadores gerais, pretende-se explorar abordagens otimistas que visam paralelizar de maneira agressiva ao invés de conservadora~\cite{chen03,williams96,williams99}, tais como abordagens evolutivas auxiliadas por técnicas de \textit{profiling} e aprendizagem de máquina.

%\FIXME{Breakdown your approach to research themes. Make it 
%clear what problem each theme tries to solve and what's the
%output of each theme.}

\subsection{Tema 1: Um modelo de otimização}

A fim de superar as limitações da paralelização automática baseada em análise estática, temos a intenção de definir um modelo de otimização para paralelização baseado em otimização discreta. Um modelo de otimização discreta permite usar várias técnicas de programação inteira, como a computação evolucionária, \textit{simulated annealing}, \textit{hill climbing} e outros. Enquanto essa abordagem não é limitada por mecanismos de análise de dependências, vários desafios precisam ser abordados.

Durante o processo de otimização, cada solução intermediária é avaliada por meio de técnicas de \textit{profiling}. Avaliar eficientemente cada indivíduo é importante para reduzir a latência envolvida em todo processo de paralelização usando uma abordagem evolutiva. Algumas das estratégias para avaliar eficientemente incluem realizar amostragem ou estimar o desempenho o desempenho do código paralelizado~\cite{douskos11,misailovic11,zhu12,fahringer95b,fahringer00,fahringer11}.

\subsection{Tema 2: Paralelização para sistemas heterogêneos e consumo de energia}

Apesar de que paralelização automática têm sido amplamente estudada, ainda há muito a ser explorado em relação ao consumo de energia, arquiteturas de computação embarcada~\cite{cordes10} ou emergentes~\cite{leung09,baskaran10,amini12,govindarajan13}, como processadores massivamente paralelos, incluindo unidades de processamento gráfico (GPUs) ou processadores de muitos núcleos integrados (MICs).

Vários novos desafios são adicionados quando paralelizamos para sistemas heterogêneos. Além de identificar laços paralelizáveis, deve-se também decidir, para cada laço, se a paralelização do laço será rentável, e em caso afirmativo, onde ele deve ser executado, ou seja, se será executado na CPU, GPU, ou qualquer outro processador paralelo disponível~\cite{tournavitis09,wang14a,leung09}. Em um sistema heterogêneo, além do desempenho bruto de cada processador, sincronização, comunicação de dados ou até mesmo o consumo de energia também devem ser considerados quando se avalia como o mapeamento paralelo deve ser realizado.

Temos a intenção de estender o modelo de otimização discreta, a fim de suportar paralelização sensível à consumo energéticos, além de integrar com arquiteturas heterogêneas, como MICs e GPUs. O modelo de otimização deve considerar a rentabilidade da paralelização para a arquitetura disponível, resultando em um modelo que engloba mapeamento portátil.

\subsection{Tema 3: Solução de violações de dependência durante o tempo de execução}

Abordagens otimistas para paralelização automática produzem soluções probabilística. Se uma solução probabilística for inaceitável, podemos usar técnicas especulativas para detectar violações de dependência em tempo de execução para re-executar seções conflitantes, fornecendo soluções precisas. Este mecanismo de controle de dependência pode ser totalmente implementado em software, semelhante ao Softspec~\cite{bruening98}, permitindo que esta técnica seja utilizada em hardwares paralelos comuns. Embora este mecanismo garante a correção, ele adiciona alguns custos para a execução como um todo, o que precisa ser devidamente equilibrado com questões de desempenho.

Também é possível integrar técnicas de paralelização dinâmica, tais como as utilizadas em análises híbridas~\cite{rus03}, que combinam a análise estática com análises em tempo de execução de referências de memória em uma única plataforma. No contexto de sistemas heterogêneos, Govindarajan e Anantpur~\cite{govindarajan13} descrevem um algoritmo que é capaz de calcular as dependências de memória em tempo de execução, onde a computação de dependências e a computação real são executadas diretamente em uma GPU.

\section{Plano de pesquisa}

\begin{description}

\item[Ano 1] Vou realizar uma extensa revisão da literatura na área, identificar pontos fracos e fortes das abordagens atuais em paralelização automática. O modelo de otimização discreta (Tema 1) destina-se a ser desenvolvido durante o primeiro ano.

\item[Ano 2] Vou estender o modelo de otimização considerando o consumo de energia. Depois, a paralelização automática será integrada com arquiteturas heterogêneas (Tema 2). Um ou dois artigos são esperados durante o segundo ano.

\item[Ano 3] Durante o terceiro ano, a paralelização automática otimista será estendida com soluções para as violações de dependência durante o tempo de execução (tema 3). Um ou dois artigos, bem como a tese de Ph.D. são esperados durante o terceiro e último ano.

\end{description}

\subsection{Resultados esperados}

Nesta pesquisa, esperamos melhorar o estado-da-arte em paralelização automática sensível ao consumo de energia para sistemas heterogêneos, superando algumas das limitações dos mecanismos atuais de análise de dependências. Os resultados produzidos por esta pesquisa devem ser publicados nas principais revistas e conferências da área.

%\FIXME{We need a conclusion section and timetable here}

\bibliographystyle{abbrv}
\bibliography{ref}
\end{document}
